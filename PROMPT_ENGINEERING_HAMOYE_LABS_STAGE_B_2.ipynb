{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Prompt Engineering Basics**|"
      ],
      "metadata": {
        "id": "RiiW8fvmrkGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LABS 2 FROM HAMOYE"
      ],
      "metadata": {
        "id": "yRURNRUZLMmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "#!pip install openai==v0.28.1\n",
        "!pip install --upgrade python-dotenv\n",
        "#!pip install --upgrade langchain\n"
      ],
      "metadata": {
        "id": "WCRefUOoNTRN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4izsYt7oT-b",
        "outputId": "f1854836-b964-46d5-ca23-134c565dbc33"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.23.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''text-davinci-003'''"
      ],
      "metadata": {
        "id": "n8ItJSKToRbu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fc3e26ce-53ae-4eae-d2da-96ff0f493ef9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'text-davinci-003'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "fxAtloU3LVEc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "EHUYbwyUMbUG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_open_param(model = 'gpt-3.5-turbo-instruct',temperature = 0.7,max_tokens = 256, top_p = 1, frequency_penalty = 0,presence_penalty = 0 ):\n",
        "  \"\"\"set the optional parameters\"\"\"\n",
        "  openai_params = {}\n",
        "\n",
        "  openai_params['model'] = model\n",
        "  openai_params['temperature'] = temperature\n",
        "  openai_params['max_tokens'] = max_tokens\n",
        "  openai_params['top_p'] = top_p\n",
        "  openai_params['frequency_penalty'] = frequency_penalty\n",
        "  openai_params['presence_penalty'] = presence_penalty\n",
        "  return openai_params\n",
        "\n"
      ],
      "metadata": {
        "id": "i7Reai0ZPJX5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n"
      ],
      "metadata": {
        "id": "8gCMtEo6zbLG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q0VjNJQe4rwB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(params, prompt):\n",
        "  \"\"\"get completion from open api\"\"\"\n",
        "  client  = OpenAI(api_key=OPENAI_API_KEY)\n",
        "  response = client.completions.create(\n",
        "      model = params['model'],\n",
        "      prompt = prompt,\n",
        "      temperature = params['temperature'],\n",
        "      max_tokens = params['max_tokens'],\n",
        "      top_p = params['top_p'],\n",
        "      frequency_penalty = params['frequency_penalty'],\n",
        "      presence_penalty = params['presence_penalty']\n",
        "  )\n",
        "\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "bcn41y6l5WVk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = set_open_param()\n",
        "params\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM24vc3X7h_F",
        "outputId": "c4ffe229-ab1d-4337-ce2f-92ab75b301e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': 'gpt-3.5-turbo-instruct',\n",
              " 'temperature': 0.7,\n",
              " 'max_tokens': 256,\n",
              " 'top_p': 1,\n",
              " 'frequency_penalty': 0,\n",
              " 'presence_penalty': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = set_open_param()\n",
        "\n",
        "prompt = \"Roses are\"\n",
        "\n",
        "response = get_completion(params, prompt)"
      ],
      "metadata": {
        "id": "Q9x0G3oc7pg9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].text\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "_G0pGLCw8Whh",
        "outputId": "2eb0ffa5-0fdf-4d74-9429-a6ab7e60fccc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " red,\nViolets are blue,\nSugar is sweet,\nAnd so are you."
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_3A76atr8l7c"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEXT SUMMARIZATION"
      ],
      "metadata": {
        "id": "O744_xgNhOMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = set_open_param()\n",
        "prompt = \"\"\" Keras is a deep learning API written in Python that runs on top of TensorFlow.\n",
        "    It is quite popular among deep learning users because of its ease of use.\n",
        "    TensorFlow is an end-to-end open-source deep learning framework developed and maintained by Google.\n",
        "    Similar to Numpy, TensorFlow allows for mathematical computations and manipulation between numerical tensors, runs on CPUs, GPUs, and TPUs.\n",
        "    Keras was incorporated in TensorFlow 2.0 (the recent version) as tf.keras (high-level API) and can run on the aforementioned hardwares.\n",
        "    TensorFlow also allows for low-level operations with the TensorFlow Core API.\n",
        "\n",
        "    Explain the above in one sentence:\"\"\"\n",
        "\n",
        "response = get_completion(params,prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "_T4iKLGqgYr9",
        "outputId": "1eca4deb-43e2-4484-bf7c-f2c7931db472"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\nKeras is a user-friendly deep learning API built on top of TensorFlow, a powerful open-source framework for numerical computation and manipulation that runs on CPUs, GPUs, and TPUs."
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Markdown('**what is the matter**')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "CNgiqmxdhsK0",
        "outputId": "e450920e-fb09-4771-97db-9c3313ae9a5e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**what is the matter**"
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question Answering"
      ],
      "metadata": {
        "id": "nU-U0ds3jAU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
        "\n",
        "Context: The Avengers were a team of extraordinary individuals, with either superpowers or other special characteristics. Though primarily affiliated with the interests of the United States of America, the group's purpose was to protect global stability from inner or extraterrestrial threats. The Avengers were first assembled by S.H.I.E.L.D. as a result of the Avengers Initiative, when Loki invaded Earth with his Chitauri army. The team, consisting of Iron Man, Captain America, Hulk, Thor, Black Widow and Hawkeye defeated Loki and went their separate ways for a while.\n",
        "\n",
        "Question: Why were the Avengers formed?\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "\n",
        "response = get_completion(params,prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "e6PkCnIiiJvp",
        "outputId": "47cd7377-019f-4045-9f4c-107b47e37ab5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " To protect global stability from inner or extraterrestrial threats."
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CODE GENERATION"
      ],
      "metadata": {
        "id": "veQAt_ILlYXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a PostgreSQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n",
        "\n",
        "response = get_completion(params, prompt)\n",
        "IPython.display.Markdown(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "V28fNSIyjur8",
        "outputId": "ad6542f9-28fd-4b2f-8d4f-d62415b32922"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\nSELECT s.StudentId, s.StudentName\nFROM students s\nINNER JOIN departments d ON s.DepartmentId = d.DepartmentId\nWHERE d.DepartmentName = 'Computer Science'"
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Markdown(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "Lkvn8R9Ilcqw",
        "outputId": "bee56c9f-2de7-44ad-97e5-669eab3c8ce6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\"\"\"\nTable departments, columns = [DepartmentId, DepartmentName]\nTable students, columns = [DepartmentId, StudentId, StudentName]\nCreate a PostgreSQL query for all students in the Computer Science Department\n\"\"\""
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jjfRps2Jlffk"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}